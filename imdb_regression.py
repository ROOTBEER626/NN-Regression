# -*- coding: utf-8 -*-
"""imdb_regression.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XXaF6Z6Y8Pl5xU6HpDGgZs7ZO_HT5d8H
"""

import pandas as pd
from google.colab import files
uploaded = files.upload()
df_train_data = pd.read_csv('train.csv',)
df_test_data = pd.read_csv('test.csv')

#df_train_data.info()
#df_train_data.describe()

df_train_data = df_train_data[['budget','popularity','revenue']] #gonna take out runtime before revenue
#df_test_data = df_test_data[['budget', 'popularity',]]

#print(df_train_data.describe())  #df_train.columns - list colum names
print(df_train_data[:3])

#df_train_data = df_train_data.dropna(axis = 0) # removes rows with null values

#df_train_data['runtime'] = df_train_data['runtime'].replace(np.nan, df_train_data['runtime'].mean())
print(df_train_data.info())
print(df_train_data.describe())

# convert to numpy
import numpy as np 
np_train_data = df_train_data.to_numpy()
np_train_data.shape

#have to convert our test data also
np_test_data = df_test_data.to_numpy()
np_test_data.shape

# normalize data
from sklearn.model_selection import train_test_split
from sklearn.preprocessing   import StandardScaler

scaler = StandardScaler()
np_train_data_scaled = scaler.fit_transform(np_train_data)

print(np_train_data[:3])
print(np_train_data_scaled.max(axis = 0))
print(np_train_data_scaled.min(axis = 0))

#Now test data
#np_test_data_scaled = scaler.fit_transform(np_test_data)

import numpy as np
import torch as t
from   matplotlib import pyplot as plt
import torch.nn.functional as F
import torch.nn as nn
from   torch.autograd import Variable

#for i in range(1,4):
#    plt.subplot(2,2,i)
#    plt.plot(np_train_data_scaled[:,i-1],np_train_data_scaled[:,-1],'.')

# split train data into train and validation (20%)
X_train, X_val, y_train, y_val = train_test_split(
    np_train_data_scaled[:,:-1], np_train_data_scaled[:,-1], test_size=0.2, shuffle = True, random_state=2)
#print(X_t_train,y_train)
#print(X_t_val, y_val)

# covert to tensors

X_t_train = t.from_numpy(X_train).float()
y_t_train = t.from_numpy(y_train).float().unsqueeze(1) 
X_t_val   = t.from_numpy(X_val).float()
y_t_val   = t.from_numpy(y_val).float().unsqueeze(1)
#gonna cut my testing data to 600 rows
#X_t_train = X_t_train[0:600,:]
#y_t_train = y_t_train[0:600, :]


#training data
print(X_t_train.shape, y_t_train.shape)
print(X_t_train.dtype, y_t_train.dtype)
#validation data
print(X_t_val.shape, y_t_val.shape)
print(X_t_val.dtype, y_t_val.dtype)

#test data
#t_test = t.from_numpy(np_test_data_scaled).float()

# DataLoader = a class that shuffles the data and splits in into batches
# you should use it during training (SGD - accumulate error over batches of data )
train_data = [(X_t_train[i], y_t_train[i]) for i in range(X_t_train.shape[0])]
print("Sample train_data = ", train_data[:3], " type = ", type(train_data))
trainloader = t.utils.data.DataLoader(train_data, batch_size = 64, shuffle=True)#reduced batch size from 64
#for x,label in trainloader:  # shuffles the data
#    print(x,label)

#Everything below here is added in meself
#So first lets build the model

#train model function
def training_loop(n_epochs, optimizer, model, loss_fn, 
                  X_t_train, X_t_val, y_t_train, y_t_val):
    for epoch in range(1, n_epochs + 1):
        # forward pass training
        y_p_train  = model(X_t_train)
        loss_train = loss_fn(y_p_train, y_t_train)
        # forward pass validation
        y_p_val    = model(X_t_val)
        loss_val   = loss_fn(y_p_val, y_t_val)
        
        # backwards training
        optimizer.zero_grad() 
        loss_train.backward()  # gradients are computed and parameters ar changed
        optimizer.step()

        if epoch == 1 or epoch % 100 == 0:
            print(f"Epoch {epoch}, Training loss {loss_train.item():.4f},"
f" Validation loss {loss_val.item():.4f}")

#class model
import torch.nn as nn
import torch.optim as optim #optimization module (SGD)
from collections import OrderedDict

n_hidden = 50
seq_model = nn.Sequential(OrderedDict([
                    ('hidden_linear', nn.Linear(2, n_hidden)),
                    ('hidden_activation', nn. ReLU()),
                    ('output_linear', nn.Linear(n_hidden, 2))
                    ]))
optimizer = optim.Adam(seq_model.parameters(), lr=1e-3) # try SGD, try other lr = 1e-3

#for name, param in seq_model.named_parameters():
#    print(name, param.shape, param)

training_loop(n_epochs    = 700, 
                optimizer = optimizer,  
                model     = seq_model,
                loss_fn   = nn.MSELoss(), 
                X_t_train = X_t_train, X_t_val= X_t_val, 
                y_t_train= y_t_train, y_t_val = y_t_val)

#This model regularly brings my Validation loss to < .4
#but I notice that after 400 Epochs the valdation rises slightly
#but still that is very good and the training loss is only sligtly lower than the validation loss 
#For this model Training Loss and Validation loss are never that far apart
#Usually within . 01
#The interesting thing about this model compared to those within fewer hidden layers is that this is the only model so far to achieve a training loss
#less than the validation loss, for all the other models with different optimization and learning rates the validation loss is less than training loss


#print('output', seq_model(X_t_val))
#print('answer', y_t_val)
#print('hidden', seq_model.hidden_linear.weight.grad, seq_model.hidden_linear.weight)

#Now I will add some other models to compare to the above 
#First I will vary the number of hidden nuerons
n_hidden = 100
seq_model2 = nn.Sequential(
    nn.Linear(2,n_hidden),
    nn.ReLU(),
    #nn.Linear(n_hidden,n_hidden),
    #nn.ReLU(),
    nn.Linear(n_hidden, 1)
)
optimizer = optim.SGD(seq_model2.parameters(),lr=.001)

#for name, param in seq_model2.named_parameters():
#  print(name, param.shape, param)

training_loop(n_epochs = 700,
              optimizer = optimizer,
              model = seq_model2,
              loss_fn = nn.MSELoss(),
              X_t_train = X_t_train, X_t_val = X_t_val,
              y_t_train = y_t_train, y_t_val = y_t_val)

#compute MSE (mean square error for regression) or accuracy for classification on the test data#I believe this is done above^
seq_model.eval()
ym_val = seq_model(X_t_val)
#loss_val = nn.MSELoss(ym_val, y_t_val)
loss_val = nn.MSELoss()
#loss_val = nn.MSELoss(y_t_train)

#doesn't give me much

#Plot Data
from matplotlib import pyplot as plt
min_val = X_t_train.min()
max_val = X_t_train.max()
print(min_val, max_val)#doesn't wanna print #so there seem to be pointers to the functions and not the actual vals
x_sample = t.arange(600).unsqueeze(1)#this should be the range of my x values
print(x_sample.shape)
#fig = plt.figure(dpi=600)
plt.xlabel("x")
plt.ylabel("y")
plt.plot(X_t_train.numpy(), y_t_train.numpy(), 'b*')
#line below is causing the error maybe run a squeen on the left argument
#plt.plot(x_sample.numpy(), seq_model2(x_sample.squeeze()).numpy(), 'c-')
#plt.plot(x_t.numpy(),      seq_model2(x_t_2d).detach().numpy(),   'ro')

#now run the model with the testing data
#So looking at the three examples the professor provided for the assignment I was able to get this far but I do not see any of them using a test set
#so I will refer to the previous examples we worked on in class and see what I can come up with
#if nothing I will slack the professor and until then i will try out different models for this problem and start working on some other problems
#Im gonna just pass the Model the testing data now
model2(test_data)